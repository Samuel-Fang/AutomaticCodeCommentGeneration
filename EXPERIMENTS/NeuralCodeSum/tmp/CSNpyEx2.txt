08/16/2020 11:28:06 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name CSNpython --data_dir ../../data/ --model_dir ../../tmp --model_name CSNpyEx2 --train_src train/code.original_subtoken --train_tgt train/javadoc.original --dev_src dev/code.original_subtoken --dev_tgt dev/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 600 --max_tgt_len 30 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 32 --use_neg_dist True --nlayers 6 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.5 --copy_attn True --early_stop 20 --warmup_steps 1000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True ]
08/16/2020 11:28:06 PM: [ ---------------------------------------------------------------------------------------------------- ]
08/16/2020 11:28:06 PM: [ Load and process data files ]
08/16/2020 11:28:17 PM: [ Num train examples = 109348 ]
08/16/2020 11:28:17 PM: [ Dataset weights = {4: 1.0} ]
08/16/2020 11:28:18 PM: [ Num dev examples = 5343 ]
08/16/2020 11:28:18 PM: [ ---------------------------------------------------------------------------------------------------- ]
08/16/2020 11:28:18 PM: [ Training model from scratch... ]
08/16/2020 11:28:18 PM: [ ---------------------------------------------------------------------------------------------------- ]
08/16/2020 11:28:18 PM: [ Build word dictionary ]
08/16/2020 11:28:27 PM: [ Num words in source = 50000 and target = 30000 ]
08/16/2020 11:28:27 PM: [ Trainable #parameters [encoder-decoder] 44.2M [total] 86M ]
08/16/2020 11:28:27 PM: [ Breakdown of the trainable paramters
+------------------------------------------------------------------------------+--------------+----------+
| Layer Name                                                                   | Output Shape |  Param # |
+------------------------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight                | [50000, 512] | 25600000 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight                | [30000, 512] | 15360000 |
| embedder.tgt_pos_embeddings.weight                                           |    [32, 512] |    16384 |
| encoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_k.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.attention.relative_positions_embeddings_v.weight |     [65, 64] |     4160 |
| encoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias                     |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight                             |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                               |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight                           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias                             |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                                |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                                  |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight                          |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias                            |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight                        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias                          |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight                       |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight                              |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                                |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight                 |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias                   |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight                       |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias                         |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight                   |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias                     |        [512] |      512 |
| generator.bias                                                               |      [30000] |    30000 |
| copy_attn.linear_in.weight                                                   |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                                  |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                                            |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                                              |          [1] |        1 |
+------------------------------------------------------------------------------+--------------+----------+ ]
08/16/2020 11:28:30 PM: [ ---------------------------------------------------------------------------------------------------- ]
08/16/2020 11:28:30 PM: [ Make data loaders ]
08/16/2020 11:28:30 PM: [ ---------------------------------------------------------------------------------------------------- ]
08/16/2020 11:28:30 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": true,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "CSNpython"
    ],
    "dataset_weights": {
        "4": 1.0
    },
    "dev_src": [
        "dev/code.original_subtoken"
    ],
    "dev_src_files": [
        "../../data/CSNpython/dev/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_tgt": [
        "dev/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/CSNpython/dev/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.5,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/CSNpyEx2.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        32
    ],
    "max_src_len": 600,
    "max_tgt_len": 30,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/CSNpyEx2.mdl",
    "model_name": "CSNpyEx2",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 6,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 109348,
    "only_test": false,
    "optimizer": "adam",
    "parallel": true,
    "pred_file": "../../tmp/CSNpyEx2.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_files": [
        "../../data/CSNpython/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/CSNpython/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 1000,
    "weight_decay": 0
} ]
08/16/2020 11:28:30 PM: [ ---------------------------------------------------------------------------------------------------- ]
08/16/2020 11:28:30 PM: [ Starting training... ]
08/17/2020 12:03:43 AM: [ train: Epoch 1 | perplexity = 21945.95 | ml_loss = 213.70 | Time for epoch = 2113.29 (s) ]
08/17/2020 12:07:10 AM: [ dev valid official: Epoch = 1 | bleu = 8.20 | rouge_l = 13.47 | Precision = 10.87 | Recall = 20.28 | F1 = 13.21 | examples = 5312 | valid time = 201.96 (s) ]
08/17/2020 12:07:10 AM: [ Best valid: bleu = 8.20 (epoch 1, 3417 updates) ]
08/17/2020 12:43:28 AM: [ train: Epoch 2 | perplexity = 5112.61 | ml_loss = 70.51 | Time for epoch = 2177.20 (s) ]
08/17/2020 12:46:54 AM: [ dev valid official: Epoch = 2 | bleu = 11.81 | rouge_l = 19.49 | Precision = 21.67 | Recall = 23.55 | F1 = 20.25 | examples = 5312 | valid time = 199.61 (s) ]
08/17/2020 12:46:54 AM: [ Best valid: bleu = 11.81 (epoch 2, 6834 updates) ]
08/17/2020 01:22:58 AM: [ train: Epoch 3 | perplexity = 101.53 | ml_loss = 44.02 | Time for epoch = 2161.48 (s) ]
08/17/2020 01:26:22 AM: [ dev valid official: Epoch = 3 | bleu = 15.16 | rouge_l = 22.15 | Precision = 25.50 | Recall = 23.74 | F1 = 23.29 | examples = 5312 | valid time = 199.16 (s) ]
08/17/2020 01:26:22 AM: [ Best valid: bleu = 15.16 (epoch 3, 10251 updates) ]
08/17/2020 02:01:33 AM: [ train: Epoch 4 | perplexity = 66.52 | ml_loss = 40.20 | Time for epoch = 2108.12 (s) ]
08/17/2020 02:04:59 AM: [ dev valid official: Epoch = 4 | bleu = 15.75 | rouge_l = 19.81 | Precision = 25.47 | Recall = 20.07 | F1 = 21.26 | examples = 5312 | valid time = 200.80 (s) ]
08/17/2020 02:04:59 AM: [ Best valid: bleu = 15.75 (epoch 4, 13668 updates) ]
08/17/2020 02:41:28 AM: [ train: Epoch 5 | perplexity = 54.51 | ml_loss = 38.34 | Time for epoch = 2187.38 (s) ]
08/17/2020 02:44:53 AM: [ dev valid official: Epoch = 5 | bleu = 14.98 | rouge_l = 23.33 | Precision = 26.49 | Recall = 25.94 | F1 = 24.66 | examples = 5312 | valid time = 199.39 (s) ]
08/17/2020 03:24:00 AM: [ train: Epoch 6 | perplexity = 46.71 | ml_loss = 36.90 | Time for epoch = 2347.39 (s) ]
08/17/2020 03:27:25 AM: [ dev valid official: Epoch = 6 | bleu = 16.15 | rouge_l = 22.93 | Precision = 28.72 | Recall = 23.41 | F1 = 24.38 | examples = 5312 | valid time = 200.13 (s) ]
08/17/2020 03:27:25 AM: [ Best valid: bleu = 16.15 (epoch 6, 20502 updates) ]
08/17/2020 04:02:45 AM: [ train: Epoch 7 | perplexity = 41.19 | ml_loss = 35.67 | Time for epoch = 2118.74 (s) ]
08/17/2020 04:06:11 AM: [ dev valid official: Epoch = 7 | bleu = 15.70 | rouge_l = 23.51 | Precision = 27.09 | Recall = 25.50 | F1 = 24.80 | examples = 5312 | valid time = 200.13 (s) ]
08/17/2020 04:45:09 AM: [ train: Epoch 8 | perplexity = 36.31 | ml_loss = 34.53 | Time for epoch = 2337.18 (s) ]
08/17/2020 04:48:35 AM: [ dev valid official: Epoch = 8 | bleu = 15.31 | rouge_l = 22.61 | Precision = 27.06 | Recall = 24.30 | F1 = 23.93 | examples = 5312 | valid time = 198.62 (s) ]
08/17/2020 05:24:05 AM: [ train: Epoch 9 | perplexity = 32.64 | ml_loss = 33.46 | Time for epoch = 2129.89 (s) ]
08/17/2020 05:27:32 AM: [ dev valid official: Epoch = 9 | bleu = 15.79 | rouge_l = 22.71 | Precision = 27.95 | Recall = 23.71 | F1 = 24.08 | examples = 5312 | valid time = 200.00 (s) ]
08/17/2020 06:06:44 AM: [ train: Epoch 10 | perplexity = 29.11 | ml_loss = 32.44 | Time for epoch = 2351.30 (s) ]
08/17/2020 06:10:08 AM: [ dev valid official: Epoch = 10 | bleu = 15.90 | rouge_l = 22.74 | Precision = 27.03 | Recall = 24.19 | F1 = 24.07 | examples = 5312 | valid time = 197.97 (s) ]
08/17/2020 06:48:56 AM: [ train: Epoch 11 | perplexity = 26.30 | ml_loss = 31.47 | Time for epoch = 2328.17 (s) ]
08/17/2020 06:52:21 AM: [ dev valid official: Epoch = 11 | bleu = 15.51 | rouge_l = 23.74 | Precision = 26.21 | Recall = 26.90 | F1 = 25.10 | examples = 5312 | valid time = 198.85 (s) ]
08/17/2020 07:28:54 AM: [ train: Epoch 12 | perplexity = 23.94 | ml_loss = 30.53 | Time for epoch = 2192.64 (s) ]
08/17/2020 07:32:18 AM: [ dev valid official: Epoch = 12 | bleu = 15.65 | rouge_l = 23.33 | Precision = 27.63 | Recall = 25.26 | F1 = 24.70 | examples = 5312 | valid time = 197.69 (s) ]
08/17/2020 08:08:52 AM: [ train: Epoch 13 | perplexity = 21.74 | ml_loss = 29.64 | Time for epoch = 2194.66 (s) ]
08/17/2020 08:12:16 AM: [ dev valid official: Epoch = 13 | bleu = 15.85 | rouge_l = 23.71 | Precision = 27.77 | Recall = 25.70 | F1 = 25.04 | examples = 5312 | valid time = 198.86 (s) ]
08/17/2020 08:47:58 AM: [ train: Epoch 14 | perplexity = 19.82 | ml_loss = 28.73 | Time for epoch = 2142.30 (s) ]
08/17/2020 08:51:22 AM: [ dev valid official: Epoch = 14 | bleu = 16.18 | rouge_l = 22.56 | Precision = 27.30 | Recall = 23.93 | F1 = 24.05 | examples = 5312 | valid time = 197.36 (s) ]
08/17/2020 08:51:22 AM: [ Best valid: bleu = 16.18 (epoch 14, 47838 updates) ]
08/17/2020 11:54:14 AM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name CSNpython --data_dir ../../data/ --model_dir ../../tmp --model_name CSNpyEx2 --train_src train/code.original_subtoken --train_tgt train/javadoc.original --dev_src dev/code.original_subtoken --dev_tgt dev/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 600 --max_tgt_len 30 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 32 --use_neg_dist True --nlayers 6 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.5 --copy_attn True --early_stop 20 --warmup_steps 1000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True ]
08/17/2020 11:54:14 AM: [ ---------------------------------------------------------------------------------------------------- ]
08/17/2020 11:54:14 AM: [ Load and process data files ]
08/17/2020 11:54:26 AM: [ Num train examples = 109348 ]
08/17/2020 11:54:26 AM: [ Dataset weights = {4: 1.0} ]
08/17/2020 11:54:27 AM: [ Num dev examples = 5343 ]
08/17/2020 11:54:27 AM: [ ---------------------------------------------------------------------------------------------------- ]
08/17/2020 11:54:27 AM: [ Found a checkpoint... ]
08/17/2020 11:54:27 AM: [ Loading model ../../tmp/CSNpyEx2.mdl.checkpoint ]
08/17/2020 11:54:48 AM: [ ---------------------------------------------------------------------------------------------------- ]
08/17/2020 11:54:48 AM: [ Make data loaders ]
08/17/2020 11:54:48 AM: [ ---------------------------------------------------------------------------------------------------- ]
08/17/2020 11:54:48 AM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": true,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "CSNpython"
    ],
    "dataset_weights": {
        "4": 1.0
    },
    "dev_src": [
        "dev/code.original_subtoken"
    ],
    "dev_src_files": [
        "../../data/CSNpython/dev/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_tgt": [
        "dev/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/CSNpython/dev/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.5,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/CSNpyEx2.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        32
    ],
    "max_src_len": 600,
    "max_tgt_len": 30,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/CSNpyEx2.mdl",
    "model_name": "CSNpyEx2",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 6,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 109348,
    "only_test": false,
    "optimizer": "adam",
    "parallel": true,
    "pred_file": "../../tmp/CSNpyEx2.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_files": [
        "../../data/CSNpython/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/CSNpython/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 1000,
    "weight_decay": 0
} ]
08/17/2020 11:54:48 AM: [ ---------------------------------------------------------------------------------------------------- ]
08/17/2020 11:54:48 AM: [ Starting training... ]
08/17/2020 12:29:49 PM: [ train: Epoch 15 | perplexity = 18.08 | ml_loss = 27.84 | Time for epoch = 2101.59 (s) ]
08/17/2020 12:33:15 PM: [ dev valid official: Epoch = 15 | bleu = 15.76 | rouge_l = 23.35 | Precision = 26.67 | Recall = 25.72 | F1 = 24.68 | examples = 5312 | valid time = 201.14 (s) ]
08/17/2020 12:33:15 PM: [ Best valid: bleu = 15.76 (epoch 15, 51255 updates) ]
08/17/2020 01:09:22 PM: [ train: Epoch 16 | perplexity = 16.20 | ml_loss = 26.84 | Time for epoch = 2164.91 (s) ]
08/17/2020 01:12:43 PM: [ dev valid official: Epoch = 16 | bleu = 15.84 | rouge_l = 22.89 | Precision = 27.41 | Recall = 24.61 | F1 = 24.35 | examples = 5312 | valid time = 198.26 (s) ]
08/17/2020 01:12:43 PM: [ Best valid: bleu = 15.84 (epoch 16, 54672 updates) ]
08/17/2020 01:48:39 PM: [ train: Epoch 17 | perplexity = 14.64 | ml_loss = 25.84 | Time for epoch = 2154.84 (s) ]
08/17/2020 01:52:05 PM: [ dev valid official: Epoch = 17 | bleu = 15.84 | rouge_l = 22.76 | Precision = 27.14 | Recall = 24.46 | F1 = 24.23 | examples = 5312 | valid time = 198.97 (s) ]
08/17/2020 01:52:05 PM: [ Best valid: bleu = 15.84 (epoch 17, 58089 updates) ]
08/17/2020 02:27:10 PM: [ train: Epoch 18 | perplexity = 13.29 | ml_loss = 24.90 | Time for epoch = 2103.81 (s) ]
08/17/2020 02:30:31 PM: [ dev valid official: Epoch = 18 | bleu = 15.76 | rouge_l = 22.91 | Precision = 26.28 | Recall = 25.41 | F1 = 24.38 | examples = 5312 | valid time = 198.21 (s) ]
08/17/2020 03:06:56 PM: [ train: Epoch 19 | perplexity = 12.04 | ml_loss = 23.97 | Time for epoch = 2184.97 (s) ]
08/17/2020 03:10:22 PM: [ dev valid official: Epoch = 19 | bleu = 15.60 | rouge_l = 24.02 | Precision = 26.61 | Recall = 26.95 | F1 = 25.33 | examples = 5312 | valid time = 199.60 (s) ]
08/17/2020 03:49:25 PM: [ train: Epoch 20 | perplexity = 10.85 | ml_loss = 23.07 | Time for epoch = 2343.03 (s) ]
08/17/2020 03:52:50 PM: [ dev valid official: Epoch = 20 | bleu = 15.84 | rouge_l = 22.06 | Precision = 26.22 | Recall = 23.69 | F1 = 23.47 | examples = 5312 | valid time = 198.66 (s) ]
08/17/2020 04:28:16 PM: [ train: Epoch 21 | perplexity = 10.07 | ml_loss = 22.24 | Time for epoch = 2125.63 (s) ]
08/17/2020 04:31:42 PM: [ dev valid official: Epoch = 21 | bleu = 15.53 | rouge_l = 22.91 | Precision = 25.91 | Recall = 25.82 | F1 = 24.38 | examples = 5312 | valid time = 199.66 (s) ]
08/17/2020 05:10:39 PM: [ train: Epoch 22 | perplexity = 9.10 | ml_loss = 21.39 | Time for epoch = 2337.07 (s) ]
08/17/2020 05:14:02 PM: [ dev valid official: Epoch = 22 | bleu = 15.65 | rouge_l = 21.99 | Precision = 26.06 | Recall = 23.98 | F1 = 23.43 | examples = 5312 | valid time = 198.02 (s) ]
